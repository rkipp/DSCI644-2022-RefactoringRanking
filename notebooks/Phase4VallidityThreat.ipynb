{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7a918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad739c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfff66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CommitId</th>\n",
       "      <th>RefactoringType</th>\n",
       "      <th>FilePath</th>\n",
       "      <th>Class</th>\n",
       "      <th>RefactoringDetail</th>\n",
       "      <th>Message</th>\n",
       "      <th>AuthorName</th>\n",
       "      <th>AuthorEmail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>a3af1683e63c9c800f486552e7e5002c24b6712b</td>\n",
       "      <td>Move Source Folder</td>\n",
       "      <td>src</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Move Source Folder\\tsrc to hibernate-validator...</td>\n",
       "      <td>Moved the legacy validator code into hibernate...</td>\n",
       "      <td>Hardy Ferentschik</td>\n",
       "      <td>hibernate@ferentschik.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>6d6c3deaf0b499e06077383d8d3add43f30ba099</td>\n",
       "      <td>Move Source Folder</td>\n",
       "      <td>hibernate-validator-legacy/src</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Move Source Folder\\thibernate-validator-legacy...</td>\n",
       "      <td>Refactored build so that compile and test can ...</td>\n",
       "      <td>Hardy Ferentschik</td>\n",
       "      <td>hibernate@ferentschik.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>6d6c3deaf0b499e06077383d8d3add43f30ba099</td>\n",
       "      <td>Move Source Folder</td>\n",
       "      <td>hibernate-validator-legacy/src/test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Move Source Folder\\thibernate-validator-legacy...</td>\n",
       "      <td>Refactored build so that compile and test can ...</td>\n",
       "      <td>Hardy Ferentschik</td>\n",
       "      <td>hibernate@ferentschik.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>25350de39ef9484997999f6e6d8f00abc5d51546</td>\n",
       "      <td>Extract Variable</td>\n",
       "      <td>hibernate-validator/src/main/java/org/hibernat...</td>\n",
       "      <td>org.hibernate.validation.engine.ValidatorImpl</td>\n",
       "      <td>Extract Variable\\tleafBeanInstance : Object in...</td>\n",
       "      <td>BVAL-37 ConstraintDescriptor.getLeafValue()\\n\\...</td>\n",
       "      <td>Emmanuel Bernard</td>\n",
       "      <td>emmanuel@hibernate.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>25350de39ef9484997999f6e6d8f00abc5d51546</td>\n",
       "      <td>Rename Method</td>\n",
       "      <td>hibernate-validator/src/main/java/org/hibernat...</td>\n",
       "      <td>org.hibernate.validation.engine.ValidatorImpl</td>\n",
       "      <td>Rename Method\\tpublic getBeanConstraints() : E...</td>\n",
       "      <td>BVAL-37 ConstraintDescriptor.getLeafValue()\\n\\...</td>\n",
       "      <td>Emmanuel Bernard</td>\n",
       "      <td>emmanuel@hibernate.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name                                  CommitId  \\\n",
       "0  hibernate$hibernate-validator  a3af1683e63c9c800f486552e7e5002c24b6712b   \n",
       "1  hibernate$hibernate-validator  6d6c3deaf0b499e06077383d8d3add43f30ba099   \n",
       "2  hibernate$hibernate-validator  6d6c3deaf0b499e06077383d8d3add43f30ba099   \n",
       "3  hibernate$hibernate-validator  25350de39ef9484997999f6e6d8f00abc5d51546   \n",
       "4  hibernate$hibernate-validator  25350de39ef9484997999f6e6d8f00abc5d51546   \n",
       "\n",
       "      RefactoringType                                           FilePath  \\\n",
       "0  Move Source Folder                                                src   \n",
       "1  Move Source Folder                     hibernate-validator-legacy/src   \n",
       "2  Move Source Folder                hibernate-validator-legacy/src/test   \n",
       "3    Extract Variable  hibernate-validator/src/main/java/org/hibernat...   \n",
       "4       Rename Method  hibernate-validator/src/main/java/org/hibernat...   \n",
       "\n",
       "                                           Class  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3  org.hibernate.validation.engine.ValidatorImpl   \n",
       "4  org.hibernate.validation.engine.ValidatorImpl   \n",
       "\n",
       "                                   RefactoringDetail  \\\n",
       "0  Move Source Folder\\tsrc to hibernate-validator...   \n",
       "1  Move Source Folder\\thibernate-validator-legacy...   \n",
       "2  Move Source Folder\\thibernate-validator-legacy...   \n",
       "3  Extract Variable\\tleafBeanInstance : Object in...   \n",
       "4  Rename Method\\tpublic getBeanConstraints() : E...   \n",
       "\n",
       "                                             Message         AuthorName  \\\n",
       "0  Moved the legacy validator code into hibernate...  Hardy Ferentschik   \n",
       "1  Refactored build so that compile and test can ...  Hardy Ferentschik   \n",
       "2  Refactored build so that compile and test can ...  Hardy Ferentschik   \n",
       "3  BVAL-37 ConstraintDescriptor.getLeafValue()\\n\\...   Emmanuel Bernard   \n",
       "4  BVAL-37 ConstraintDescriptor.getLeafValue()\\n\\...   Emmanuel Bernard   \n",
       "\n",
       "                AuthorEmail  \n",
       "0  hibernate@ferentschik.de  \n",
       "1  hibernate@ferentschik.de  \n",
       "2  hibernate@ferentschik.de  \n",
       "3    emmanuel@hibernate.org  \n",
       "4    emmanuel@hibernate.org  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change this to point to wherever you've put the data\n",
    "data_dir = \"F:\\\\GoogleDrive\\\\ds_ml\\\\RIT\\\\2022-01 DSCI.644\\\\project\\\\phase2\\\\\"  # on Ryzen workstation\n",
    "# data_dir = \"D:\\\\GoogleDrive\\\\ds_ml\\\\RIT\\\\2022-01 DSCI.644\\\\project\\\\phase2\\\\\"  # on Xeon workstation\n",
    "data_path = data_dir + \"project3-authors.csv\"\n",
    "df_raw = pd.read_csv(data_path)\n",
    "# df_raw.shape   # (17317, 9)\n",
    "# df_raw.columns # ['Name', 'CommitId', 'RefactoringType', 'FilePath', 'Class',\n",
    "#                   'RefactoringDetail', 'Message', 'AuthorName', 'AuthorEmail']\n",
    "# df_raw['Name'].unique()  # ['hibernate$hibernate-validator', 'eclipse$bpmn2-modeler',\n",
    "#                             'adangel$pmd']\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed2bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'CommitId', 'RefactoringType', 'FilePath', 'Class',\n",
       "       'RefactoringDetail', 'Message', 'AuthorName', 'AuthorEmail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0a875e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CommitId</th>\n",
       "      <th>RefactoringType</th>\n",
       "      <th>FilePath</th>\n",
       "      <th>Class</th>\n",
       "      <th>RefactoringDetail</th>\n",
       "      <th>Message</th>\n",
       "      <th>AuthorName</th>\n",
       "      <th>AuthorEmail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>9e0626b8318ba4bdf55580aacae3947410278129</td>\n",
       "      <td>Extract Variable</td>\n",
       "      <td>engine/src/main/java/org/hibernate/validator/i...</td>\n",
       "      <td>org.hibernate.validator.internal.engine.Valida...</td>\n",
       "      <td>Extract Variable\\tbeanMetaData : BeanMetaData&lt;...</td>\n",
       "      <td>HV-1681 Separate out bean metadata aware Value...</td>\n",
       "      <td>marko-bekhta</td>\n",
       "      <td>marko.prykladna@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>9e0626b8318ba4bdf55580aacae3947410278129</td>\n",
       "      <td>Move Class</td>\n",
       "      <td>engine/src/main/java/org/hibernate/validator/i...</td>\n",
       "      <td>org.hibernate.validator.internal.engine.ValueC...</td>\n",
       "      <td>Move Class\\torg.hibernate.validator.internal.e...</td>\n",
       "      <td>HV-1681 Separate out bean metadata aware Value...</td>\n",
       "      <td>marko-bekhta</td>\n",
       "      <td>marko.prykladna@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>59372ef6b92138b0c6a347ea16cd655576715252</td>\n",
       "      <td>Rename Variable</td>\n",
       "      <td>engine/src/main/java/org/hibernate/validator/i...</td>\n",
       "      <td>org.hibernate.validator.internal.engine.valuee...</td>\n",
       "      <td>Rename Variable\\textractorDescriptorsToCache :...</td>\n",
       "      <td>HV-1684 Fix value extraction logic to avoid st...</td>\n",
       "      <td>Guillaume Smet</td>\n",
       "      <td>guillaume.smet@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>59372ef6b92138b0c6a347ea16cd655576715252</td>\n",
       "      <td>Rename Variable</td>\n",
       "      <td>engine/src/main/java/org/hibernate/validator/i...</td>\n",
       "      <td>org.hibernate.validator.internal.engine.valuee...</td>\n",
       "      <td>Rename Variable\\textractorDescriptorsToCache :...</td>\n",
       "      <td>HV-1684 Fix value extraction logic to avoid st...</td>\n",
       "      <td>Guillaume Smet</td>\n",
       "      <td>guillaume.smet@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>hibernate$hibernate-validator</td>\n",
       "      <td>571ab96b9ea2b32c2597f0765f59da28f5c029d9</td>\n",
       "      <td>Rename Method</td>\n",
       "      <td>engine/src/main/java/org/hibernate/validator/i...</td>\n",
       "      <td>org.hibernate.validator.internal.engine.path.P...</td>\n",
       "      <td>Rename Method\\tpublic getPathWithoutLeafNode()...</td>\n",
       "      <td>HV-1691 Rename PathImpl#getPathWithoutLeafNode...</td>\n",
       "      <td>Guillaume Smet</td>\n",
       "      <td>guillaume.smet@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name                                  CommitId  \\\n",
       "5394  hibernate$hibernate-validator  9e0626b8318ba4bdf55580aacae3947410278129   \n",
       "5395  hibernate$hibernate-validator  9e0626b8318ba4bdf55580aacae3947410278129   \n",
       "5396  hibernate$hibernate-validator  59372ef6b92138b0c6a347ea16cd655576715252   \n",
       "5397  hibernate$hibernate-validator  59372ef6b92138b0c6a347ea16cd655576715252   \n",
       "5398  hibernate$hibernate-validator  571ab96b9ea2b32c2597f0765f59da28f5c029d9   \n",
       "\n",
       "       RefactoringType                                           FilePath  \\\n",
       "5394  Extract Variable  engine/src/main/java/org/hibernate/validator/i...   \n",
       "5395        Move Class  engine/src/main/java/org/hibernate/validator/i...   \n",
       "5396   Rename Variable  engine/src/main/java/org/hibernate/validator/i...   \n",
       "5397   Rename Variable  engine/src/main/java/org/hibernate/validator/i...   \n",
       "5398     Rename Method  engine/src/main/java/org/hibernate/validator/i...   \n",
       "\n",
       "                                                  Class  \\\n",
       "5394  org.hibernate.validator.internal.engine.Valida...   \n",
       "5395  org.hibernate.validator.internal.engine.ValueC...   \n",
       "5396  org.hibernate.validator.internal.engine.valuee...   \n",
       "5397  org.hibernate.validator.internal.engine.valuee...   \n",
       "5398  org.hibernate.validator.internal.engine.path.P...   \n",
       "\n",
       "                                      RefactoringDetail  \\\n",
       "5394  Extract Variable\\tbeanMetaData : BeanMetaData<...   \n",
       "5395  Move Class\\torg.hibernate.validator.internal.e...   \n",
       "5396  Rename Variable\\textractorDescriptorsToCache :...   \n",
       "5397  Rename Variable\\textractorDescriptorsToCache :...   \n",
       "5398  Rename Method\\tpublic getPathWithoutLeafNode()...   \n",
       "\n",
       "                                                Message      AuthorName  \\\n",
       "5394  HV-1681 Separate out bean metadata aware Value...    marko-bekhta   \n",
       "5395  HV-1681 Separate out bean metadata aware Value...    marko-bekhta   \n",
       "5396  HV-1684 Fix value extraction logic to avoid st...  Guillaume Smet   \n",
       "5397  HV-1684 Fix value extraction logic to avoid st...  Guillaume Smet   \n",
       "5398  HV-1691 Rename PathImpl#getPathWithoutLeafNode...  Guillaume Smet   \n",
       "\n",
       "                    AuthorEmail  \n",
       "5394  marko.prykladna@gmail.com  \n",
       "5395  marko.prykladna@gmail.com  \n",
       "5396   guillaume.smet@gmail.com  \n",
       "5397   guillaume.smet@gmail.com  \n",
       "5398   guillaume.smet@gmail.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter for just the adangel$pmd rows\n",
    "df_adangle = df_raw[df_raw['Name'] == \"adangel$pmd\"].copy()\n",
    "\n",
    "# filter for just the hibernate$hibernate-validator rows\n",
    "df_hiber = df_raw[df_raw['Name'] == \"hibernate$hibernate-validator\"].copy()\n",
    "\n",
    "# df_hiber.shape  # (5399, 9) same row count as report in phase 1 repoort, check\n",
    "# df_adangle.shape  # (8495, 9) same row count as report in phase 1 repoort, check\n",
    "\n",
    "# reset the indices\n",
    "# df_hiber.reset_index().drop(['index'], axis=1)  # didn't do anything\n",
    "df_hiber.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297dc5d9",
   "metadata": {},
   "source": [
    "## Remove records with more than one filepath\n",
    "\n",
    "Both the adangle and hibernate projects had a small number of records that contained references to more than a single filepath.  Since these records constitute < 1% of the adangle records, we decided to remove them instead of trying coming up with a scheme to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d1ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many records have FilePath entries containing more than one path?\n",
    "# df_multi_paths_ada = df_adangle[df_adangle['FilePath'].str.contains(',')]\n",
    "# df_multi_paths_hib = df_hiber[df_hiber['FilePath'].str.contains(',')]\n",
    "# df_multi_paths_ada.shape, df_multi_paths_hib.shape  # 80/8495 ada, 19/5399 hiber, <1% so remove them\n",
    "df_ada_singles = df_adangle[df_adangle['FilePath'].str.contains(',') == False]\n",
    "df_hib_singles = df_hiber[df_hiber['FilePath'].str.contains(',') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40daa7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d561c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0fff058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_paths.to_csv(\"paths.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab43d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada_unparsed_filepath = df_ada_singles[['RefactoringType', 'FilePath', 'AuthorName']].copy()\n",
    "df_hib_unparsed_filepath = df_hib_singles[['RefactoringType', 'FilePath', 'AuthorName']].copy()\n",
    "# df_ada_unparsed_filepath.shape, df_hib_unparsed_filepath.shape  # ((8415, 3), (5380, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d87be5",
   "metadata": {},
   "source": [
    "## Author Groupings\n",
    "\n",
    "Interestingly, the same commit buckets used for the adangel project work fine for the hibernate project.  From the Phase3Explore notebook, we see the following counts in these buckets:\n",
    "\n",
    "+  3 had > 400 commits  (very high frequency committers)\n",
    "+  3 had > 100 and <= 400 commits  (high frequency committers)\n",
    "+  4 had  > 25 and <= 100 commits  (medium frequency committers)\n",
    "+ 12 had <= 25 commits  (low frequency committers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33195a98",
   "metadata": {},
   "source": [
    "## Fix Author issue in hibernate data\n",
    "\n",
    "There are two authors in the hibernate projects that cause issues if not addressed.\n",
    "1. **marko bekhta** is listed in two different ways in the data: marko.bekhta = marko-bekhta = marko bekhta\n",
    "2. The apostrophe in David D'Alto\n",
    "\n",
    "To fix issue 1., convert both forms to **marko bekhta**.  To fix issue 2., the apostrophe was removed.\n",
    "\n",
    "After fixing these issues, we put the authors into the buckets define above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d607d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hibernate issue: fix the marko.bekhta = marko-bekhta = marko bekhta issue\n",
    "df_hib_unparsed_filepath['AuthorName'] = \\\n",
    "    df_hib_unparsed_filepath['AuthorName'].str.replace('.', ' ', regex=False)\n",
    "df_hib_unparsed_filepath['AuthorName'] = \\\n",
    "    df_hib_unparsed_filepath['AuthorName'].str.replace('-', ' ', regex=False)\n",
    "# fix Davide D'Alto\n",
    "df_hib_unparsed_filepath['AuthorName'] = \\\n",
    "    df_hib_unparsed_filepath['AuthorName'].str.replace(\"'\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the committers for each bucket so we can filter on them\n",
    "\n",
    "## df_authors - a pandas df with an AuthorName column\n",
    "## \n",
    "def get_committer_buckets(df_authors, ex_high_bucket=400, high_bucket=100, med_bucket=25):\n",
    "    authors = df_authors['AuthorName'].value_counts()\n",
    "    committers_extremely_high = authors[authors > ex_high_bucket].index.to_list()\n",
    "    committers_high = authors[(authors > high_bucket) & (authors <= ex_high_bucket)].index.to_list()\n",
    "    committers_medium = authors[(authors > med_bucket) & (authors <= high_bucket)].index.to_list()\n",
    "    committers_low = authors[(authors < med_bucket)].index.to_list()\n",
    "    \n",
    "    return committers_extremely_high, committers_high, committers_medium, committers_low\n",
    "    \n",
    "author_buckets_ada = get_committer_buckets(df_ada_unparsed_filepath)\n",
    "author_buckets_hib = get_committer_buckets(df_hib_unparsed_filepath)\n",
    "# author_buckets_ada[0], author_buckets_ada[1], author_buckets_ada[2], author_buckets_ada[3]\n",
    "# author_buckets_hib[0], author_buckets_hib[1], author_buckets_hib[2], author_buckets_hib[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ab14d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_hib_unparsed_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa393fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_author_group(df_authors, committers_extremely_high, committers_high, committers_medium):\n",
    "    '''Adds an AuthorsGroup column to the input dataframe\n",
    "    \n",
    "    Args:\n",
    "        df_authors (pandas.core.frame.DataFrame): Dataframe that contains a AuthorName column\n",
    "        committers_extremely_high (list): list of names of the extremely high committers\n",
    "        committers_high (list): list of names of the high committers\n",
    "        committers_medium (list): list of names of the medium committers\n",
    "    \n",
    "    Returns:\n",
    "        pandas.core.frame.DataFrame: input dataframe with AuthorName column added\n",
    "    \n",
    "    '''\n",
    "    df_authors['AuthorGroup'] = \\\n",
    "    np.where(df_authors['AuthorName'].isin(committers_extremely_high),\n",
    "         \"extremely high\",\n",
    "         np.where(df_authors['AuthorName'].isin(committers_high),\n",
    "                  \"high\", np.where(df_authors['AuthorName'].isin(committers_medium),\n",
    "                  \"medium\", \"low\")))\n",
    "    return df_authors\n",
    "    \n",
    "\n",
    "# df_design_matrix_unparsed_filepath['AuthorGroup'] = \\\n",
    "# np.where(df_design_matrix_unparsed_filepath['AuthorName'].isin(committers_extremely_high),\n",
    "#          \"extremely high\",\n",
    "#          np.where(df_design_matrix_unparsed_filepath['AuthorName'].isin(committers_high),\n",
    "#                   \"high\", np.where(df_design_matrix_unparsed_filepath['AuthorName'].isin(committers_medium),\n",
    "#                   \"medium\", \"low\")))\n",
    "\n",
    "df_ada = create_author_group(df_ada_unparsed_filepath, author_buckets_ada[0],\n",
    "                             author_buckets_ada[1], author_buckets_ada[2])\n",
    "\n",
    "df_hib = create_author_group(df_hib_unparsed_filepath, author_buckets_hib[0],\n",
    "                             author_buckets_hib[1], author_buckets_hib[2])\n",
    "\n",
    "# check each AuthorGroup for adangle\n",
    "# df_ada[df_ada['AuthorName'].isin(author_buckets_ada[0])]  # 5940\n",
    "# df_ada[df_ada['AuthorName'].isin(author_buckets_ada[1])]  # 1772\n",
    "# df_ada[df_ada['AuthorName'].isin(author_buckets_ada[2])]  #  388\n",
    "# df_ada[df_ada['AuthorName'].isin(author_buckets_ada[3])]  #  315\n",
    "#                                                           # 8415 total, check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce14d0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 315, 0.36507936507936506) (43, 63, 0.6825396825396826)\n"
     ]
    }
   ],
   "source": [
    "# Use google docstring style to doc function:\n",
    "# https://realpython.com/documenting-python-code/#documenting-your-python-code-base-using-docstrings\n",
    "def get_shared_prop(df, left_group = 'low', right_group = 'extremely high'):\n",
    "    '''Computes the proportion of files committed by the left_group that were\n",
    "    also committed by the right_group.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.core.frame.DataFrame): dataframe with AuthorGroup and FilePath columns. The\n",
    "          AuthorGroup column is expected to contains values defined by left_group and right_group.\n",
    "        left_group (str): left group of committers for which proportion is being computed\n",
    "        right_group (str): right group of committers to check against left group\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 3-tuple where\n",
    "        tuple[0] = proportion of left_group files committed that are shared right_group commits,\n",
    "        tuple[1] = number of left_group files committed that are shared right_group commits, and\n",
    "        tuple[2] = total number of left_group files committed\n",
    "    '''\n",
    "    \n",
    "    df_right = df[df['AuthorGroup'] == right_group].copy()\n",
    "    df_right['right_row'] = df_right.index     # keep track of the rows of the right group\n",
    "    df_left = df[df['AuthorGroup'] == left_group].copy()\n",
    "    df_left['left_row'] = df_left.index        # keep track of the rows of the left group\n",
    "    df_left_merge = df_left.merge(df_right, on='FilePath', how='left').copy()\n",
    "    df_left_merge_trimmed = df_left_merge[['FilePath', 'AuthorGroup_x', 'left_row', 'right_row']]\n",
    "    # want intersection, so remove all the rows that were committed by the left_group but NOT the right\n",
    "    df_left_intersect = df_left_merge_trimmed.dropna(subset = ['right_row']).copy()\n",
    "    # If right_group larger, merge can create multiple rows per same left row. Remove these duplicates:\n",
    "    df_left_intersect.drop('right_row', axis=1, inplace=True)\n",
    "    df_left_intersect.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df_left_intersect.shape[0], df_left.shape[0], df_left_intersect.shape[0] / df_left.shape[0]\n",
    "\n",
    "# check low vs extremely high\n",
    "ada_low_props = get_shared_prop(df_ada)\n",
    "hib_low_props = get_shared_prop(df_hib)\n",
    "print(ada_low_props, hib_low_props)  # (115, 315, 0.36508) (43, 63, 0.68254) ~2x more overlap with hib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fd8322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 388, 0.24742268041237114) (78, 183, 0.4262295081967213)\n"
     ]
    }
   ],
   "source": [
    "# check medium vs extremely high\n",
    "ada_med_props = get_shared_prop(df_ada, 'medium')\n",
    "hib_med_props = get_shared_prop(df_hib, 'medium')\n",
    "print(ada_med_props, hib_med_props)  # (96, 388, 0.2474) (78, 183, 0.4262) also ~2x more overlap with hib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8214869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9b142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd911c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of proportions, H0: p_match_hib = p_match_ada, HA: p_match_hib > p_match_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e747c4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2560c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b57fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82868919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e50fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c906b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a0a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea5e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36134adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d36385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write the data to files so they can be read in and analyzed later\n",
    "# df_design_matrix.to_csv(\"df_design_matrix_hibernate.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc4e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c7c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0253f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b6b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677a2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
